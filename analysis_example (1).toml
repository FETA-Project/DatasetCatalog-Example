# INTRO
# - Please try to fill in as much fields as possible (it will be considered for overall evaluation of the dataset)
# - Keywords with "_info" trailer are used as description of the keword in the Katoda UI
# - If you need help with advanced metrics please let know soukudom@cesnet.cz
# - If it is possible share your jupyter notebooks/scripts you are using. Upload them to the gitlab and you can reference it in the description. Katoda has build in Jupyter sever.
# - Please share any feedback regarding this format to soukudom@cesnet.cz or use comments in the Katoda UI.


acronym_info = "Short name of the dataset, which is used as the unique identifier. E.g., CESNET_TLS_Year22"
acronym = ""
acronym_aliases_info = "Additional alias for the Dataset Acronym (e.g. CESNET-TLS-Year22-XS). Used to filter the different subsection of the original dataset"
acronym_aliases = ""
title_info = "Full title of the dataset. E.g., CESNET-TLS-Year22"
title = ""
paper_title_info = "Full title of the original paper with the dataset"
paper_title = ""
authors = "David Benes"
description_info = "High-level description of the dataset. E.g., TLS capture from CESNET2 backbone network over one year (2022). The capture was done using high-speed monitoring probes at the perimeter of CESNET2 network. This dataset provides realistic characteristics of traffic originating from various web browsers, operating systems, mobile devices, desktop machines, and both HTTP/1.1 and HTTP/2 protocols."
description = ""
format_info = "Dataset data format. E.g. json, csv, datazoo"
format = "datazoo"
doi_info = "DOI of this dataset"
doi = ""
origins_doi_info = "DOI of the original dataset"
origins_doi = ""
submitter = "Full Name of the submitter"
tags_info = "Use tags to categorize the dataset (comma separated)"
tags = "network traffic classfication"
url = "https://github.com/CESNET/cesnet-datazoo"


#[collection_workflow]
# data_collection_tool = "ipfixprobe"
# data_collection_year = 2022
# feature_extraction_tool_info = "Tool that converts dataset to feature dataset. If any."
# feature_extraction_tool = "ipfixprobe PSTATS, TLS"
# feature_extraction_tool_description = "ipfix probe generates extended flow format based on used modules in the ipfixprobe. Per Packet Information (PPI) is flattended and used as single features."
# capture_config_parameters_info = "specific parameters that were used to capture dataset or feature dataset" 
# capture_config_parameters = ""
# real_dataset_info = "Source of the dataset. E.g., real environment, testbed or generated."
# real_dataset = "yes"
# annotation_info = "Description of the dataset annotation. E.g., manual, automatic"
# annotation = "Automatic based on SNI field from TLS header"
 
# [generic_info]
#capture_dates_info = "When was the dataset captured/generated"
#capture_dates = "31.10.2022 - 27.11.2022"
# classes = 157
# features = 130
# f1-score_info = "F1-score calculated based on NDVM tool [https://github.com/soukudom/NDVM]"
# f1-score = "0.998"
# performance_metric_info = "Perfomance metric defined by the author. Please define full specification e.g., F1-weighted"
# performance_metric_name = ""
# performance_metric_value = ""
# label_info = "Name of the field with label. In case this is unsupervised dataset, type None"
# label = "APP"
# known_issues_info = """Description of indentified issues in the dataset"""
# known_issues = """
# * Wrong column name 
# * Wrong labels
# """
# key_observations_info = "List of known errors, drifts, limits, ... of the dataset"
# key_observations = """
# * ML performance drop without retrainig mainly in March. This drop is caused due to change in the network monitoring infrastructure. 
# * Several days missing ['20220128', '20220129', '20220130', '20221212', '20221213', '20221229', '20221230', '20221231']
# """
# dataset_organization_info = "Structure of the dataset. E.g., per day, per capture, per device"
# dataset_organization = "per day"
# dataset_organization_description_info = "Description of the content of the organization. Is there any metadata?"
# dataset_organization_description = """Dataset is accessible via Datazoo framework which allows a convenient way to get data in python including various selection options. Iteration is possible per day as author claims."""
# dataset_documentation_info = "How to get started with the dataset. Ideally add example notebook."
# dataset_documentation = """
#  This dataset is best available with the Datazoo framework. Full documentation with general Getting Started is available here https://cesnet.github.io/cesnet-datazoo/getting_started/. Basic example of getting dataframe with feature vector is available here ...
# """
# used_dataset_info = "Script to get dataset for provided analysis"
# used_dataset = "get-dataset.py"
# dataset_application_info = "Where the dataset has been already applied."
# dataset_application = """
# * https://ieeexplore.ieee.org/document/10575630
# """

# per_class_data = """
#{"class A": 273606, 
#"Class B": 265064, 
#Class C": 7755}
# """

# per_feature_data = """ 
#{"feature a": "feature a is ...",
# "feature b": "featre b is ..."}
#"""

# [dataset_drift_analysis]
# description = """Drift analysis is used to see behavior of the dataset over time. In this section, you can see a comparison of two workflows: Dataset without retraining and dataset with retraining based on drift detection described in https://github.com/FETA-Project/MFWDD.
#This description contains summary results of drift counts and features and classes that caused the most drifts. In case you would like to see more detailed insights behind these summary numbers, please visit the included jupyter notebook, where you can even run your own queries."""
# drift_workflow = "Katoda-tls-ppi-drift-insights.ipynb"
#
#[dataset_drift_analysis.drifts_count]
#without_retraining = """
#{"Not Drifted": 31,
#"Drifted": 317}
#"""
#
#retraining = """
#{"Not Drifted": 333,
#"Drifted": 13}
#"""
#
#[dataset_drift_analysis.top_5]
#classes_without_retraining = """
#{"Firefox Accounts": 346,
#"Redmine (CESNET, MFF UK, KIV ZCU)": 344,
#"Alza WebAPI": 342,
#"Mozilla Telemetry": 340,
#"Xiaomi Account API": 339}
#"""
#
#classes_retrainig = """
#{"Firefox Accounts": 244,
# "Apple Updates": 226,
# "Mozilla Telemetry": 222,
# "Aukro Backend": 216,
# "Redmine (CESNET, MFF UK, KIV ZCU)": 215}
#"""

#features_without_retraining = """
#{"SIZE_4": 326,
#"DIR_2": 322,
#"PPI_LEN":315,
#"DIR_6": 310,
#"SIZE_10": 304}
#"""
#
#features_retraining = """
# {"SIZE_1": 91,
# "DIR_30": 53,
# "DIR_29": 52,
# "DIR_28": 47,
# "DIR_27": 43}
#"""
#
#[advanced_metrics]
#description = """
# 
#Advanced metrics provides more detailed evalution of provided dataset to understand its content. List and meaning of advanced metrics is the following:
#  
# * Permutation Slope: Shows linkage between data and labels. The higher metric the dataset and original labels have stronger relationship
# * P Value Status: Categorical metric to detect permutation p-value rules
# * Redundancy: Shows percentage of data samples that can we randomly deleted. The higher metric the more redundant samples
# * Similarity: Shows similarity of selected (main) class with the rest of classes. If the metric is above 1, they are different. If the metric is below 1, there is big similarity between classes.
#Calculation is done based on the following tool: https://github.com/soukudom/NDVM
#"""
#perqoda_permutation_slope = """ 0.404336"""
#p_value_status = """ Good """
#redundancy = """ 0.9451 """
#similarity = """ 2.161246 """
#advanced_metrics_workflow = "Reporter-Drift.ipynb"
#
#[dataset_comparison]
#description = "ML model comparison for this dataset"
#use_case = """ 
# * Encrypted traffic classification: the QUIC case, accuracy 89%, multi-modal CNN
# * Hidden in Time, Revealed in #Frequency: Spectral Features and Multiresolution Analysis for Encrypted Internet Traffic Classification, accuracy 93%, F1-score 93.6%, random-forrest
#* Is Deep Learning a Better Option than Random Forest for Encrypted Traffic Classification?, accuracy 71.9%, F1-score 70.7%, random-forest
#* QUIC Traffic Classification Based on Multi-Feature Fusion, accuracy 99.95%; used SNI as categorycal feature 
#"""
#similar_dataset = """ 
# * VisQUIC
# * UCDAVIS19
# * MIRAGE-19
# * MIRAGE-22
# * UTMOBILENET21 
#"""
## format: id, doi, title, [cited/used,comment/comparison]\n

#Currently there is no dataset from the different time or network segment to run this evaluation.
#"""
